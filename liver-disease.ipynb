{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9257006,"sourceType":"datasetVersion","datasetId":5510012}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\n\n# Parameters\nbatch_size = 32\nepochs = 10\nlearning_rate = 0.001\ntrain_test_split_ratio = 0.75\n\n# Data Transformations\ndata_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Dataset Path (Replace 'your_dataset_path' with the actual path)\ndata_dir = '/kaggle/input/liver-histopathology-fibrosis-ultrasound-images/Dataset/Dataset'\ndataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n\n# Verify number of classes\nnum_classes = len(dataset.classes)\nprint(f\"Number of classes: {num_classes}\")\nassert num_classes == 5, \"The dataset must have exactly 5 classes.\"\n\n# Train-Test Split\ntrain_size = int(train_test_split_ratio * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Load Pretrained ResNet Model\nmodel = models.resnet50(pretrained=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, num_classes)  # Adjusting output layer for 5 classes\n\n# Define Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Training Loop\nprint(\"Starting Training...\")\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc = 100. * correct / total\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n\n# Testing Loop\nprint(\"\\nStarting Testing...\")\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\nfinal_loss = test_loss / len(test_loader)\nfinal_acc = 100. * correct / total\nprint(f\"Test Loss: {final_loss:.4f}, Test Accuracy: {final_acc:.2f}%\")\n\n# Save the trained model\nmodel_save_path = 'resnet50_fibrosis_model.pth'\ntorch.save(model.state_dict(), model_save_path)\nprint(f\"Model saved to {model_save_path}\")\n\n# If running on Kaggle, provide a download link\nfrom IPython.display import FileLink\nFileLink(model_save_path)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T10:06:29.595913Z","iopub.execute_input":"2025-01-27T10:06:29.596254Z","iopub.status.idle":"2025-01-27T10:15:12.805191Z","shell.execute_reply.started":"2025-01-27T10:06:29.596225Z","shell.execute_reply":"2025-01-27T10:15:12.804473Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 5\nStarting Training...\nEpoch 1/10, Loss: 0.8832, Accuracy: 62.15%\nEpoch 2/10, Loss: 0.6669, Accuracy: 71.02%\nEpoch 3/10, Loss: 0.5386, Accuracy: 77.46%\nEpoch 4/10, Loss: 0.4329, Accuracy: 82.62%\nEpoch 5/10, Loss: 0.3576, Accuracy: 86.04%\nEpoch 6/10, Loss: 0.2669, Accuracy: 89.54%\nEpoch 7/10, Loss: 0.2469, Accuracy: 90.95%\nEpoch 8/10, Loss: 0.2063, Accuracy: 92.60%\nEpoch 9/10, Loss: 0.1213, Accuracy: 95.36%\nEpoch 10/10, Loss: 0.0701, Accuracy: 97.68%\n\nStarting Testing...\nTest Loss: 0.7427, Test Accuracy: 80.77%\nModel saved to resnet50_fibrosis_model.pth\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/resnet50_fibrosis_model.pth","text/html":"<a href='resnet50_fibrosis_model.pth' target='_blank'>resnet50_fibrosis_model.pth</a><br>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\n\n# Parameters\nbatch_size = 32\nepochs = 10\nlearning_rate = 0.001\ntrain_test_split_ratio = 0.80\n\n# Data Transformations\ndata_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Dataset Path (Replace 'your_dataset_path' with the actual path)\ndata_dir = '/kaggle/input/liver-histopathology-fibrosis-ultrasound-images/Dataset/Dataset'\ndataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n\n# Verify number of classes\nnum_classes = len(dataset.classes)\nprint(f\"Number of classes: {num_classes}\")\nassert num_classes == 5, \"The dataset must have exactly 5 classes.\"\n\n# Train-Test Split\ntrain_size = int(train_test_split_ratio * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Define a Custom Residual Block\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = nn.Conv2d(out_channels, out_channels * 4, kernel_size=1, stride=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_channels * 4)\n        self.downsample = downsample\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        identity = x\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n# Load Pretrained ResNet Model with Custom Bottleneck Layers\nclass CustomResNet(nn.Module):\n    def __init__(self, block, layers, num_classes):\n        super(CustomResNet, self).__init__()\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * 4, num_classes)\n\n    def _make_layer(self, block, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels * 4:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * 4, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * 4),\n            )\n\n        layers = []\n        layers.append(block(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels * 4\n        for _ in range(1, blocks):\n            layers.append(block(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x\n\n# Instantiate Custom ResNet\nmodel = CustomResNet(ResidualBlock, [3, 4, 6, 3], num_classes)\n\n# Define Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Training Loop\nprint(\"Starting Training...\")\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc = 100. * correct / total\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n\n# Testing Loop\nprint(\"\\nStarting Testing...\")\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\nfinal_loss = test_loss / len(test_loader)\nfinal_acc = 100. * correct / total\nprint(f\"Test Loss: {final_loss:.4f}, Test Accuracy: {final_acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:10:38.08561Z","iopub.execute_input":"2024-12-22T16:10:38.085909Z","iopub.status.idle":"2024-12-22T16:19:19.028233Z","shell.execute_reply.started":"2024-12-22T16:10:38.085887Z","shell.execute_reply":"2024-12-22T16:19:19.027423Z"}},"outputs":[],"execution_count":null}]}